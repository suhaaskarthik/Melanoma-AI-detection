{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 63056,
          "databundleVersionId": 9094797,
          "sourceType": "competition"
        },
        {
          "sourceId": 192132114,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 192953104,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 193443610,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 195481859,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Fork of ISIC 2024 |Â Only Tabular Data + OverSample",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhaaskarthik/Melanoma-AI-detection/blob/main/metadata-ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "7WJAwRQlL2iB"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "isic_2024_challenge_path = kagglehub.competition_download('isic-2024-challenge')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "kheTQ_OaL2iD"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "import optuna"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-09-06T08:48:48.90007Z",
          "iopub.execute_input": "2024-09-06T08:48:48.900793Z",
          "iopub.status.idle": "2024-09-06T08:48:48.907183Z",
          "shell.execute_reply.started": "2024-09-06T08:48:48.900758Z",
          "shell.execute_reply": "2024-09-06T08:48:48.906213Z"
        },
        "trusted": true,
        "id": "ViGDjC6gL2iE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, gc, time, copy, glob, random, logging\n",
        "from collections import defaultdict\n",
        "import h5py\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torch.cuda import amp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from colorama import Fore, Back, Style\n",
        "b_ = Fore.BLUE\n",
        "sr_ = Style.RESET_ALL\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# # Logger\n",
        "logger = logging.getLogger('train-logger')\n",
        "# Initialize\n",
        "if logger.hasHandlers():\n",
        "    logger.handlers.clear()\n",
        "# Set handler\n",
        "file_handler = logging.FileHandler('training.log', 'a', 'utf-8')\n",
        "file_handler.setLevel(logging.INFO)\n",
        "console_handler = logging.StreamHandler()\n",
        "console_handler.setLevel(logging.INFO)\n",
        "# Formater\n",
        "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "file_handler.setFormatter(formatter)\n",
        "console_handler.setFormatter(formatter)\n",
        "\n",
        "logger.addHandler(file_handler)\n",
        "logger.addHandler(console_handler)\n",
        "logger.setLevel(logging.INFO)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:48:52.211624Z",
          "iopub.execute_input": "2024-09-06T08:48:52.211983Z",
          "iopub.status.idle": "2024-09-06T08:48:52.223534Z",
          "shell.execute_reply.started": "2024-09-06T08:48:52.211954Z",
          "shell.execute_reply": "2024-09-06T08:48:52.222544Z"
        },
        "trusted": true,
        "id": "VoOr7x9aL2iE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR = \"/kaggle/input/isic-2024-challenge\"\n",
        "TRAIN_DIR = f'{ROOT_DIR}/train-image/image'\n",
        "TEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\n",
        "TEST_CSV = f'{ROOT_DIR}/test-metadata.csv'\n",
        "SUBM_CSV = f'{ROOT_DIR}/sample_submission.csv'\n",
        "\n",
        "\n",
        "CONFIG = {\n",
        "    \"seed\": 42,\n",
        "    \"epochs\": 6,\n",
        "    \"img_size\": 224,\n",
        "    \"model_name\": \"convnext_base\",\n",
        "    \"model_name\": \"tf_efficientnet_b0_ns\",\n",
        "    \"checkpoint_path\" : \"/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b0/1/tf_efficientnet_b0_aa-827b6e33.pth\",\n",
        "    \"train_batch_size\": 32,\n",
        "    \"valid_batch_size\": 64,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"scheduler\": 'CosineAnnealingLR',\n",
        "    \"min_lr\": 1e-6,\n",
        "    \"T_max\": 500,\n",
        "    \"weight_decay\": 1e-5, # 1e-6,\n",
        "    \"fold\" : 0,\n",
        "    \"n_fold\": 5,\n",
        "    \"n_accumulate\": 1,\n",
        "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    \"save_model\": True\n",
        "}\n",
        "\n",
        "def set_seed(seed=CONFIG['seed']):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:48:55.484321Z",
          "iopub.execute_input": "2024-09-06T08:48:55.484706Z",
          "iopub.status.idle": "2024-09-06T08:48:55.494057Z",
          "shell.execute_reply.started": "2024-09-06T08:48:55.484679Z",
          "shell.execute_reply": "2024-09-06T08:48:55.493161Z"
        },
        "trusted": true,
        "id": "X2t28wmIL2iF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG['gem_p'] = 2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:48:59.046046Z",
          "iopub.execute_input": "2024-09-06T08:48:59.046742Z",
          "iopub.status.idle": "2024-09-06T08:48:59.051119Z",
          "shell.execute_reply.started": "2024-09-06T08:48:59.046707Z",
          "shell.execute_reply": "2024-09-06T08:48:59.049995Z"
        },
        "trusted": true,
        "id": "_c-pNPI-L2iF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ComboIter(object):\n",
        "    \"\"\"An iterator.\"\"\"\n",
        "    def __init__(self, my_loader):\n",
        "        self.my_loader = my_loader\n",
        "        self.loader_iters = [iter(loader) for loader in self.my_loader.loaders]\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        # When the shortest loader (the one with minimum number of batches)\n",
        "        # terminates, this iterator will terminates.\n",
        "        # The `StopIteration` raised inside that shortest loader's `__next__`\n",
        "        # method will in turn gets out of this `__next__` method.\n",
        "        batches = [loader_iter.__next__() for loader_iter in self.loader_iters]\n",
        "        return self.my_loader.combine_batch(batches)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.my_loader)\n",
        "\n",
        "class ComboLoader(object):\n",
        "    def __init__(self, loaders):\n",
        "        self.loaders = loaders\n",
        "\n",
        "    def __iter__(self):\n",
        "        return ComboIter(self)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min([len(loader) for loader in self.loaders])\n",
        "\n",
        "    # Customize the behavior of combining batches here.\n",
        "    def combine_batch(self, batches):\n",
        "        return batches\n",
        "\n",
        "def get_sampling_probabilities(class_count, mode='instance', ep=None, n_eps=None):\n",
        "    '''\n",
        "    Note that for progressive sampling I use n_eps-1, which I find more intuitive.\n",
        "    If you are training for 10 epochs, you pass n_eps=10 to this function. Then, inside\n",
        "    the training loop you would have sth like 'for ep in range(n_eps)', so ep=0,...,9,\n",
        "    and all fits together.\n",
        "    '''\n",
        "    if mode == 'instance':\n",
        "        q = 0\n",
        "    elif mode == 'class':\n",
        "        q = 1\n",
        "    elif mode == 'sqrt':\n",
        "        q = 0.5 # 1/2\n",
        "    elif mode == 'cbrt':\n",
        "        q = 0.125 # 1/8\n",
        "    elif mode == 'prog':\n",
        "        assert ep != None and n_eps != None, 'progressive sampling requires to pass values for ep and n_eps'\n",
        "        relative_freq_imbal = class_count ** 0 / (class_count ** 0).sum()\n",
        "        relative_freq_bal = class_count ** 1 / (class_count ** 1).sum()\n",
        "        sampling_probabilities_imbal = relative_freq_imbal ** (-1)\n",
        "        sampling_probabilities_bal = relative_freq_bal ** (-1)\n",
        "        return (1 - ep / (n_eps - 1)) * sampling_probabilities_imbal + (ep / (n_eps - 1)) * sampling_probabilities_bal\n",
        "    else: sys.exit('not a valid mode')\n",
        "\n",
        "    relative_freq = class_count ** q / (class_count ** q).sum()\n",
        "    sampling_probabilities = relative_freq ** (-1)\n",
        "\n",
        "    return sampling_probabilities\n",
        "\n",
        "def modify_loader(loader, mode, ep=None, n_eps=None):\n",
        "    class_count = np.unique(loader.dataset.targets, return_counts=True)[1]\n",
        "    sampling_probs = get_sampling_probabilities(class_count, mode=mode, ep=ep, n_eps=n_eps)\n",
        "    sample_weights = sampling_probs[loader.dataset.targets]\n",
        "\n",
        "    mod_sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights))\n",
        "    mod_loader = DataLoader(loader.dataset, batch_size = loader.batch_size, sampler=mod_sampler, num_workers=loader.num_workers)\n",
        "    return mod_loader\n",
        "\n",
        "def get_combo_loader(loader, base_sampling='instance'):\n",
        "    if base_sampling == 'instance':\n",
        "        imbalanced_loader = loader\n",
        "    else:\n",
        "        imbalanced_loader = modify_loader(loader, mode=base_sampling)\n",
        "\n",
        "    balanced_loader = modify_loader(loader, mode='class')\n",
        "    combo_loader = ComboLoader([imbalanced_loader, balanced_loader])\n",
        "    return combo_loader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:00.610924Z",
          "iopub.execute_input": "2024-09-06T08:49:00.611695Z",
          "iopub.status.idle": "2024-09-06T08:49:00.628134Z",
          "shell.execute_reply.started": "2024-09-06T08:49:00.611661Z",
          "shell.execute_reply": "2024-09-06T08:49:00.627331Z"
        },
        "trusted": true,
        "id": "4Dr1V2QwL2iF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(f\"{ROOT_DIR}/train-metadata.csv\")\n",
        "print(\"          \\t| df.shape   \\t| # of positive cases \\t| # of patients\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"original \\t| {df.shape} \\t| {df.target.sum()} \\t\\t| {df.patient_id.unique().shape}\")\n",
        "\n",
        "# Add file path\n",
        "def get_train_file_path(image_id):\n",
        "    return f\"{TRAIN_DIR}/{image_id}.jpg\"\n",
        "\n",
        "df['file_path'] = df['isic_id'].apply(get_train_file_path)\n",
        "train_images = sorted(glob.glob(f\"{TRAIN_DIR}/*.jpg\"))\n",
        "df = df[df['file_path'].isin(train_images)].reset_index(drop=True)\n",
        "\n",
        "# Add fold\n",
        "N_SPLITS = 5\n",
        "sgkf = StratifiedGroupKFold(n_splits=CONFIG['n_fold'])\n",
        "\n",
        "for fold, (_, val_) in enumerate(sgkf.split(df, df.target, df.patient_id)):\n",
        "    df.loc[val_, \"kfold\"] = int(fold)\n",
        "\n",
        "df.tail(3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:06.918281Z",
          "iopub.execute_input": "2024-09-06T08:49:06.918689Z",
          "iopub.status.idle": "2024-09-06T08:49:16.375426Z",
          "shell.execute_reply.started": "2024-09-06T08:49:06.918657Z",
          "shell.execute_reply": "2024-09-06T08:49:16.374385Z"
        },
        "trusted": true,
        "id": "yw5dBFi9L2iF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ISICDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df\n",
        "        self.isic_id = df[\"isic_id\"].values\n",
        "        self.file_names = df['file_path'].values\n",
        "        self.targets = df['target'].values\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        isic_id = self.isic_id[index]\n",
        "        img_path = self.file_names[index]\n",
        "        target = self.targets[index]\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)[\"image\"]\n",
        "\n",
        "        return {\n",
        "            'isic_id': isic_id,\n",
        "            'image': img,\n",
        "            'target': target\n",
        "        }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:16.376958Z",
          "iopub.execute_input": "2024-09-06T08:49:16.37729Z",
          "iopub.status.idle": "2024-09-06T08:49:16.385458Z",
          "shell.execute_reply.started": "2024-09-06T08:49:16.377262Z",
          "shell.execute_reply": "2024-09-06T08:49:16.384348Z"
        },
        "trusted": true,
        "id": "AaC9e7y4L2iG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "\n",
        "    \"train\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.Flip(p=0.5),\n",
        "        A.Downscale(p=0.25),\n",
        "        A.ShiftScaleRotate(shift_limit=0.1,\n",
        "                           scale_limit=0.15,\n",
        "                           rotate_limit=60,\n",
        "                           p=0.5),\n",
        "        A.HueSaturationValue(\n",
        "                hue_shift_limit=0.2,\n",
        "                sat_shift_limit=0.2,\n",
        "                val_shift_limit=0.2,\n",
        "                p=0.5\n",
        "            ),\n",
        "        A.RandomBrightnessContrast(\n",
        "                brightness_limit=(-0.1,0.1),\n",
        "                contrast_limit=(-0.1, 0.1),\n",
        "                p=0.5\n",
        "            ),\n",
        "        A.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "                max_pixel_value=255.0,\n",
        "                p=1.0\n",
        "            ),\n",
        "        ToTensorV2()], p=1.),\n",
        "\n",
        "    \"valid\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.RandomRotate90(p=0.5), A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5), A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "        A.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "                max_pixel_value=255.0,\n",
        "                p=1.0\n",
        "            ),\n",
        "        ToTensorV2()], p=1.)\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:18.538212Z",
          "iopub.execute_input": "2024-09-06T08:49:18.538613Z",
          "iopub.status.idle": "2024-09-06T08:49:18.548805Z",
          "shell.execute_reply.started": "2024-09-06T08:49:18.538582Z",
          "shell.execute_reply": "2024-09-06T08:49:18.547846Z"
        },
        "trusted": true,
        "id": "j5CSWrKlL2iG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class GeM(nn.Module):\n",
        "    def __init__(self, gem_p, eps=1e-6):\n",
        "        super(GeM, self).__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1)*gem_p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gem(x, p=self.p, eps=self.eps)\n",
        "\n",
        "    def gem(self, x, p, eps=1e-6):\n",
        "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + \\\n",
        "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
        "                ', ' + 'eps=' + str(self.eps) + ')'\n",
        "\n",
        "class ISICModel(nn.Module):\n",
        "    def __init__(self, model_name, num_classes=1, pretrained=False, checkpoint_path=None, gem_p=3):\n",
        "        super(ISICModel, self).__init__()\n",
        "\n",
        "        self.model = timm.create_model(\n",
        "            model_name=CONFIG['model_name'],\n",
        "            pretrained=pretrained,\n",
        "            in_chans=3, num_classes=0, global_pool=''\n",
        "        )\n",
        "        if checkpoint_path:\n",
        "            model_weight = torch.load(checkpoint_path)\n",
        "            model_weight = {k: v for k, v in model_weight.items() if \"classifier\" not in k}\n",
        "            self.model.load_state_dict(model_weight)\n",
        "        self.pooling = GeM(gem_p)\n",
        "\n",
        "        dim_features = 1280 # for eff_b0\n",
        "        self.target = nn.Linear(dim_features, 1)\n",
        "        self.dropout = nn.ModuleList([\n",
        "\t\t\tnn.Dropout(0.5) for i in range(5)\n",
        "\t\t])\n",
        "\n",
        "    def forward(self, images):\n",
        "        batch_size = len(images)\n",
        "        features = self.model(images)\n",
        "        pool = self.pooling(features).flatten(1)\n",
        "        logit=0\n",
        "        for i in range(len(self.dropout)):\n",
        "            logit += self.target(self.dropout[i](pool))\n",
        "        logit = logit/len(self.dropout)\n",
        "        return logit\n",
        "\n",
        "\n",
        "# # Test\n",
        "model = ISICModel(CONFIG['model_name'], CONFIG['checkpoint_path'])\n",
        "model.to(CONFIG['device']);"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:21.226178Z",
          "iopub.execute_input": "2024-09-06T08:49:21.226834Z",
          "iopub.status.idle": "2024-09-06T08:49:21.383314Z",
          "shell.execute_reply.started": "2024-09-06T08:49:21.226793Z",
          "shell.execute_reply": "2024-09-06T08:49:21.382553Z"
        },
        "trusted": true,
        "id": "MhvyoalnL2iG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def criterion(outputs, targets):\n",
        "    return nn.BCELoss()(outputs, targets)\n",
        "\n",
        "# pAUC score\n",
        "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80) -> float:\n",
        "    '''\n",
        "    2024 ISIC Challenge metric: pAUC\n",
        "\n",
        "    Given a solution file and submission file, this function returns the\n",
        "    the partial area under the receiver operating characteristic (pAUC)\n",
        "    above a given true positive rate (TPR) = 0.80.\n",
        "    https://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve.\n",
        "\n",
        "    (c) 2024 Nicholas R Kurtansky, MSKCC\n",
        "\n",
        "    Args:\n",
        "        solution: ground truth pd.DataFrame of 1s and 0s\n",
        "        submission: solution dataframe of predictions of scores ranging [0, 1]\n",
        "\n",
        "    Returns:\n",
        "        Float value range [0, max_fpr]\n",
        "    '''\n",
        "\n",
        "    del solution[row_id_column_name]\n",
        "    del submission[row_id_column_name]\n",
        "\n",
        "    # Check if all values in solution['target'] are 1 or 1\n",
        "    if solution.values.sum() == len(solution) or solution.values.sum() == 0.0:\n",
        "        raise ValueError(\"\")\n",
        "\n",
        "    # rescale the target. set 0s to 1s and 1s to 0s (since sklearn only has max_fpr)\n",
        "    v_gt = abs(np.asarray(solution.values)-1)\n",
        "\n",
        "    # flip the submissions to their compliments\n",
        "    v_pred = -1.0*np.asarray(submission.values)\n",
        "\n",
        "    max_fpr = abs(1-min_tpr)\n",
        "\n",
        "    # using sklearn.metric functions: (1) roc_curve and (2) auc\n",
        "    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n",
        "    if max_fpr is None or max_fpr == 1:\n",
        "        return auc(fpr, tpr)\n",
        "    if max_fpr <= 0 or max_fpr > 1:\n",
        "        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n",
        "\n",
        "    # Add a single point at max_fpr by linear interpolation\n",
        "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
        "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
        "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
        "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
        "    fpr = np.append(fpr[:stop], max_fpr)\n",
        "    partial_auc = auc(fpr, tpr)\n",
        "\n",
        "    return partial_auc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:24.367815Z",
          "iopub.execute_input": "2024-09-06T08:49:24.368646Z",
          "iopub.status.idle": "2024-09-06T08:49:24.379286Z",
          "shell.execute_reply.started": "2024-09-06T08:49:24.368608Z",
          "shell.execute_reply": "2024-09-06T08:49:24.378288Z"
        },
        "trusted": true,
        "id": "EKK_gW3XL2iG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "preds_dict = {}\n",
        "for fold in range(CONFIG['n_fold']):\n",
        "        print(f\"##### fold {fold} ######\")\n",
        "        # Model\n",
        "        model = ISICModel(\n",
        "            CONFIG['model_name'],\n",
        "            pretrained=False,\n",
        "            gem_p=CONFIG['gem_p']\n",
        "        )\n",
        "        trained_weight = glob.glob(f'/kaggle/input/infer-from-only-images-with-balanced-mixup/fold{fold}_pAUC*.bin')[0]\n",
        "        model.load_state_dict(torch.load(trained_weight))\n",
        "        model.to(CONFIG['device']);\n",
        "        # Data loader\n",
        "        df_valid = df[df.kfold == fold].reset_index(drop=True) # OOF data\n",
        "        valid_dataset = ISICDataset(df_valid, transforms=data_transforms[\"valid\"])\n",
        "        valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'],\n",
        "                                  num_workers=2, shuffle=False, pin_memory=True)\n",
        "        # Infer\n",
        "        bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n",
        "        for step, data in bar:\n",
        "            images = data['image'].to(CONFIG[\"device\"], dtype=torch.float)\n",
        "            isic_ids = data['isic_id']\n",
        "            batch_size = images.size(0)\n",
        "            logits = model(images)\n",
        "            outputs = torch.sigmoid(logits)\n",
        "            preds = outputs.detach().cpu().numpy()\n",
        "            for i in range(batch_size):\n",
        "                preds_dict[isic_ids[i]] = preds[i][0]\n",
        "\n",
        "df['preds'] = df['isic_id'].map(preds_dict)\n",
        "df.to_csv('preds.csv')\n",
        "\n",
        "# Score\n",
        "true_df = pd.read_csv(f\"{ROOT_DIR}/train-metadata.csv\")[['isic_id', 'target']]\n",
        "pred_df = pd.read_csv('preds.csv')[['isic_id', 'preds']]\n",
        "val_score = score(true_df, pred_df, \"isic_id\")\n",
        "print(val_score)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:27.147275Z",
          "iopub.execute_input": "2024-09-06T08:49:27.14814Z",
          "iopub.status.idle": "2024-09-06T08:49:31.134866Z",
          "shell.execute_reply.started": "2024-09-06T08:49:27.148094Z",
          "shell.execute_reply": "2024-09-06T08:49:31.133565Z"
        },
        "trusted": true,
        "id": "aHFh-3c8L2iH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "root = Path('/kaggle/input/isic-2024-challenge')\n",
        "\n",
        "train_path = root / 'train-metadata.csv'\n",
        "test_path = root / 'test-metadata.csv'\n",
        "subm_path = root / 'sample_submission.csv'\n",
        "\n",
        "id_col = 'isic_id'\n",
        "target_col = 'target'\n",
        "group_col = 'patient_id'\n",
        "\n",
        "err = 1e-5\n",
        "sampling_ratio = 0.01\n",
        "seed = 42\n",
        "\n",
        "num_cols = [\n",
        "    'age_approx',                        # Approximate age of patient at time of imaging.\n",
        "    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n",
        "    'tbp_lv_A',                          # A inside  lesion.+\n",
        "    'tbp_lv_Aext',                       # A outside lesion.+\n",
        "    'tbp_lv_B',                          # B inside  lesion.+\n",
        "    'tbp_lv_Bext',                       # B outside lesion.+\n",
        "    'tbp_lv_C',                          # Chroma inside  lesion.+\n",
        "    'tbp_lv_Cext',                       # Chroma outside lesion.+\n",
        "    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n",
        "    'tbp_lv_Hext',                       # Hue outside lesion.+\n",
        "    'tbp_lv_L',                          # L inside lesion.+\n",
        "    'tbp_lv_Lext',                       # L outside lesion.+\n",
        "    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n",
        "    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n",
        "    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n",
        "    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n",
        "    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n",
        "    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n",
        "    'tbp_lv_deltaLB',                    #\n",
        "    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n",
        "    'tbp_lv_eccentricity',               # Eccentricity.+\n",
        "    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n",
        "    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n",
        "    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n",
        "    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n",
        "    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n",
        "    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n",
        "    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n",
        "    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n",
        "    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n",
        "    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n",
        "    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n",
        "    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n",
        "    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n",
        "]\n",
        "\n",
        "\n",
        "new_num_cols = [\n",
        "    'lesion_size_ratio',             # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n",
        "    'lesion_shape_index',            # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n",
        "    'hue_contrast',                  # tbp_lv_H                - tbp_lv_Hext              abs\n",
        "    'luminance_contrast',            # tbp_lv_L                - tbp_lv_Lext              abs\n",
        "    'lesion_color_difference',       # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt\n",
        "    'border_complexity',             # tbp_lv_norm_border      + tbp_lv_symm_2axis\n",
        "    'color_uniformity',              # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n",
        "\n",
        "    'position_distance_3d',          # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n",
        "    'perimeter_to_area_ratio',       # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n",
        "    'area_to_perimeter_ratio',       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n",
        "    'lesion_visibility_score',       # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n",
        "    'symmetry_border_consistency',   # tbp_lv_symm_2axis       * tbp_lv_norm_border\n",
        "    'consistency_symmetry_border',   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n",
        "\n",
        "    'color_consistency',             # tbp_lv_stdL             / tbp_lv_Lext\n",
        "    'consistency_color',             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n",
        "    'size_age_interaction',          # clin_size_long_diam_mm  * age_approx\n",
        "    'hue_color_std_interaction',     # tbp_lv_H                * tbp_lv_color_std_mean\n",
        "    'lesion_severity_index',         # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n",
        "    'shape_complexity_index',        # border_complexity       + lesion_shape_index\n",
        "    'color_contrast_index',          # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n",
        "\n",
        "    'log_lesion_area',               # tbp_lv_areaMM2          + 1  np.log\n",
        "    'normalized_lesion_size',        # clin_size_long_diam_mm  / age_approx\n",
        "    'mean_hue_difference',           # tbp_lv_H                + tbp_lv_Hext    / 2\n",
        "    'std_dev_contrast',              # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n",
        "    'color_shape_composite_index',   # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n",
        "    'lesion_orientation_3d',         # tbp_lv_y                , tbp_lv_x  np.arctan2\n",
        "    'overall_color_difference',      # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n",
        "\n",
        "    'symmetry_perimeter_interaction',# tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n",
        "    'comprehensive_lesion_index',    # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n",
        "    'color_variance_ratio',          # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n",
        "    'border_color_interaction',      # tbp_lv_norm_border      * tbp_lv_norm_color\n",
        "    'border_color_interaction_2',\n",
        "    'size_color_contrast_ratio',     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n",
        "    'age_normalized_nevi_confidence',# tbp_lv_nevi_confidence  / age_approx\n",
        "    'age_normalized_nevi_confidence_2',\n",
        "    'color_asymmetry_index',         # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n",
        "\n",
        "    'volume_approximation_3d',       # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n",
        "    'color_range',                   # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n",
        "    'shape_color_consistency',       # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n",
        "    'border_length_ratio',           # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n",
        "    'age_size_symmetry_index',       # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n",
        "    'index_age_size_symmetry',       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution']\n",
        "norm_cols = [f'{col}_patient_norm' for col in num_cols + new_num_cols]\n",
        "special_cols = ['count_per_patient']\n",
        "feature_cols = num_cols + new_num_cols + cat_cols + norm_cols + special_cols"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:38.584174Z",
          "iopub.execute_input": "2024-09-06T08:49:38.584772Z",
          "iopub.status.idle": "2024-09-06T08:49:38.600956Z",
          "shell.execute_reply.started": "2024-09-06T08:49:38.584739Z",
          "shell.execute_reply": "2024-09-06T08:49:38.600232Z"
        },
        "trusted": true,
        "id": "VnYHBKAWL2iH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(path):\n",
        "    return (\n",
        "        pl.read_csv(path)\n",
        "        .with_columns(\n",
        "            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n",
        "        )\n",
        "        .with_columns(\n",
        "            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()), # You may want to impute test data with train\n",
        "        )\n",
        "        .with_columns(\n",
        "            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n",
        "            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n",
        "            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n",
        "            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n",
        "            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n",
        "            border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n",
        "            color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n",
        "        )\n",
        "        .with_columns(\n",
        "            position_distance_3d           = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n",
        "            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n",
        "            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n",
        "            lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n",
        "            combined_anatomical_site       = pl.col('anatom_site_general') + '_' + pl.col('tbp_lv_location'),\n",
        "            symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n",
        "            consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n",
        "        )\n",
        "        .with_columns(\n",
        "            color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n",
        "            consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n",
        "            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n",
        "            hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n",
        "            lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n",
        "            shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n",
        "            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n",
        "        )\n",
        "        .with_columns(\n",
        "            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n",
        "            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n",
        "            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n",
        "            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n",
        "            color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n",
        "            lesion_orientation_3d          = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n",
        "            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n",
        "        )\n",
        "        .with_columns(\n",
        "            symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n",
        "            comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n",
        "            color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n",
        "            border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n",
        "            border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n",
        "            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n",
        "            age_normalized_nevi_confidence = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n",
        "            age_normalized_nevi_confidence_2 = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n",
        "            color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n",
        "        )\n",
        "        .with_columns(\n",
        "            volume_approximation_3d        = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n",
        "            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n",
        "            shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n",
        "            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n",
        "            age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n",
        "            index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n",
        "        )\n",
        "        .with_columns(\n",
        "            ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols)\n",
        "        )\n",
        "        .with_columns(\n",
        "            count_per_patient = pl.col('isic_id').count().over('patient_id'),\n",
        "        )\n",
        "        .with_columns(\n",
        "            pl.col(cat_cols).cast(pl.Categorical),\n",
        "        )\n",
        "        .to_pandas()\n",
        "        .set_index(id_col)\n",
        "    )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:42.95576Z",
          "iopub.execute_input": "2024-09-06T08:49:42.956141Z",
          "iopub.status.idle": "2024-09-06T08:49:42.986104Z",
          "shell.execute_reply.started": "2024-09-06T08:49:42.9561Z",
          "shell.execute_reply": "2024-09-06T08:49:42.98523Z"
        },
        "trusted": true,
        "id": "lmcjwWFiL2iH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df_train, df_test):\n",
        "    global cat_cols\n",
        "\n",
        "    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n",
        "    encoder.fit(df_train[cat_cols])\n",
        "\n",
        "    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n",
        "\n",
        "    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n",
        "    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n",
        "\n",
        "    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n",
        "    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n",
        "\n",
        "    for col in cat_cols:\n",
        "        feature_cols.remove(col)\n",
        "\n",
        "    feature_cols.extend(new_cat_cols)\n",
        "    cat_cols = new_cat_cols\n",
        "\n",
        "    return df_train, df_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:45.68098Z",
          "iopub.execute_input": "2024-09-06T08:49:45.681575Z",
          "iopub.status.idle": "2024-09-06T08:49:45.68907Z",
          "shell.execute_reply.started": "2024-09-06T08:49:45.68154Z",
          "shell.execute_reply": "2024-09-06T08:49:45.68813Z"
        },
        "trusted": true,
        "id": "A5WNWIZeL2iH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_metric(estimator, X, y_true):\n",
        "    y_hat = estimator.predict_proba(X)[:, 1]\n",
        "    min_tpr = 0.80\n",
        "    max_fpr = abs(1 - min_tpr)\n",
        "\n",
        "    v_gt = abs(y_true - 1)\n",
        "    v_pred = np.array([1.0 - x for x in y_hat])\n",
        "\n",
        "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
        "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
        "\n",
        "    return partial_auc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:49.316349Z",
          "iopub.execute_input": "2024-09-06T08:49:49.317086Z",
          "iopub.status.idle": "2024-09-06T08:49:49.326214Z",
          "shell.execute_reply.started": "2024-09-06T08:49:49.317053Z",
          "shell.execute_reply": "2024-09-06T08:49:49.325007Z"
        },
        "trusted": true,
        "id": "MfZhjhWaL2iH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Read & Feature Engineering"
      ],
      "metadata": {
        "id": "Ua4V-d11L2iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = read_data(train_path)\n",
        "df_test = read_data(test_path)\n",
        "df_subm = pd.read_csv(subm_path, index_col=id_col)\n",
        "\n",
        "df_train, df_test = preprocess(df_train, df_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:49:51.829583Z",
          "iopub.execute_input": "2024-09-06T08:49:51.830278Z",
          "iopub.status.idle": "2024-09-06T08:49:57.400227Z",
          "shell.execute_reply.started": "2024-09-06T08:49:51.830245Z",
          "shell.execute_reply": "2024-09-06T08:49:57.3991Z"
        },
        "trusted": true,
        "id": "uhv6qapDL2iI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#they are detected at the first run\n",
        "least_important_features = ['onehot_32', 'onehot_6', 'onehot_33', 'onehot_30', 'onehot_26', 'onehot_22', 'onehot_36', 'onehot_4']\n",
        "#they are detected after the least_important_features are removed and it has increased cv score also so I add it\n",
        "#least_important_features_2 = ['onehot_17', 'onehot_42', 'onehot_29', 'onehot_13', 'onehot_25']\n",
        "#least_important_features += least_important_features_2\n",
        "df_train.drop(columns =least_important_features,inplace = True)\n",
        "for feature in least_important_features:\n",
        "    cat_cols.remove(feature)\n",
        "    feature_cols.remove(feature)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:50:01.457096Z",
          "iopub.execute_input": "2024-09-06T08:50:01.457579Z",
          "iopub.status.idle": "2024-09-06T08:50:01.664048Z",
          "shell.execute_reply.started": "2024-09-06T08:50:01.457544Z",
          "shell.execute_reply": "2024-09-06T08:50:01.663076Z"
        },
        "trusted": true,
        "id": "NZ23Gew2L2iI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "oof_image_net_preds = pd.read_csv(\"/kaggle/working/preds.csv\")\n",
        "\n",
        "\n",
        "# Rename the 'oof_prediction' column to 'imagenet_predict'\n",
        "image_pred_col = \"imagenet_predict\"\n",
        "oof_image_net_preds = oof_image_net_preds.rename(columns={'preds': image_pred_col})\n",
        "\n",
        "# Merge with df_train on 'isic_id', adding both 'fold' and the prediction column\n",
        "df_train = df_train.merge(oof_image_net_preds[['isic_id', image_pred_col]],\n",
        "                          on='isic_id',\n",
        "                          how='left')\n",
        "\n",
        "# Add the new column to feature_cols\n",
        "feature_cols_without_img = copy.deepcopy(feature_cols)\n",
        "feature_cols.append(image_pred_col)\n",
        "\n",
        "# Print some information about the merged dataframe\n",
        "print(f\"Shape of df_train after merge: {df_train.shape}\")\n",
        "print(f\"Number of null values in {image_pred_col}: {df_train[image_pred_col].isnull().sum()}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:50:18.369234Z",
          "iopub.execute_input": "2024-09-06T08:50:18.36993Z",
          "iopub.status.idle": "2024-09-06T08:50:24.444867Z",
          "shell.execute_reply.started": "2024-09-06T08:50:18.369896Z",
          "shell.execute_reply": "2024-09-06T08:50:24.443963Z"
        },
        "trusted": true,
        "id": "0F9Bha-jL2iJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:50:49.20007Z",
          "iopub.execute_input": "2024-09-06T08:50:49.200717Z",
          "iopub.status.idle": "2024-09-06T08:50:49.230795Z",
          "shell.execute_reply.started": "2024-09-06T08:50:49.200686Z",
          "shell.execute_reply": "2024-09-06T08:50:49.229892Z"
        },
        "trusted": true,
        "id": "AnlG_HMLL2iJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ISICDataset_for_test(Dataset):\n",
        "    def __init__(self, df, file_hdf, transforms=None):\n",
        "        self.df = df\n",
        "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
        "        self.isic_ids = df.index.values\n",
        "        self.targets = df['target'].values\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.isic_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        isic_id = self.isic_ids[index]\n",
        "        img = np.array( Image.open(BytesIO(self.fp_hdf[isic_id][()])) )\n",
        "        target = self.targets[index]\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)[\"image\"]\n",
        "\n",
        "        return {\n",
        "            'isic_id': isic_id,\n",
        "            'image': img,\n",
        "            'target': target,\n",
        "        }\n",
        "\n",
        "#df_test = pd.read_csv(TEST_CSV)\n",
        "df_test['target'] = 0 # dummy\n",
        "test_dataset = ISICDataset_for_test(df_test, TEST_HDF, transforms=data_transforms[\"valid\"])\n",
        "test_loader = DataLoader(test_dataset, batch_size=CONFIG['valid_batch_size'],\n",
        "                          num_workers=2, shuffle=False, pin_memory=True)\n",
        "\n",
        "test_dataset1 = ISICDataset_for_test(df_test, TEST_HDF, transforms=data_transforms[\"valid\"])\n",
        "test_loader1 = DataLoader(test_dataset1, batch_size=CONFIG['valid_batch_size'],\n",
        "                          num_workers=2, shuffle=False, pin_memory=True)\n",
        "\n",
        "test_dataset2 = ISICDataset_for_test(df_test, TEST_HDF, transforms=data_transforms[\"valid\"])\n",
        "test_loader2 = DataLoader(test_dataset2, batch_size=CONFIG['valid_batch_size'],\n",
        "                          num_workers=2, shuffle=False, pin_memory=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_preds = np.zeros(len(df_test))\n",
        "    for fold in range(CONFIG['n_fold']):\n",
        "        fold_preds = []\n",
        "        fold_preds1 = []\n",
        "        fold_preds2 = []\n",
        "        # Load model\n",
        "        model = ISICModel(CONFIG['model_name'],\n",
        "                          pretrained=False,\n",
        "                          gem_p=CONFIG['gem_p'])\n",
        "        trained_weight = glob.glob(f'/kaggle/input/infer-from-only-images-with-balanced-mixup/fold{fold}_pAUC*.bin')[0]\n",
        "        print(trained_weight)\n",
        "        # trained_weight = glob.glob(CONFIG['trained_checkpoint_path'] + f'/fold{fold}*.bin')[0]\n",
        "        model.load_state_dict(torch.load(trained_weight))\n",
        "        model.to(CONFIG['device']);\n",
        "\n",
        "        # Infer\n",
        "        bar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
        "        for step, data in bar:\n",
        "            images = data['image'].to(CONFIG[\"device\"], dtype=torch.float)\n",
        "            batch_size = images.size(0)\n",
        "            logits = model(images)\n",
        "            outputs = torch.sigmoid(logits)\n",
        "            fold_preds.append(outputs.detach().cpu().numpy())\n",
        "        bar1 = tqdm(enumerate(test_loader1), total=len(test_loader1))\n",
        "        for step, data in bar1:\n",
        "            images = data['image'].to(CONFIG[\"device\"], dtype=torch.float)\n",
        "            batch_size = images.size(0)\n",
        "            logits = model(images)\n",
        "            outputs = torch.sigmoid(logits)\n",
        "            fold_preds1.append(outputs.detach().cpu().numpy())\n",
        "        bar2 = tqdm(enumerate(test_loader2), total=len(test_loader2))\n",
        "        for step, data in bar2:\n",
        "            images = data['image'].to(CONFIG[\"device\"], dtype=torch.float)\n",
        "            batch_size = images.size(0)\n",
        "            logits = model(images)\n",
        "            outputs = torch.sigmoid(logits)\n",
        "            fold_preds2.append(outputs.detach().cpu().numpy())\n",
        "\n",
        "        fold_preds = np.concatenate(fold_preds).flatten()\n",
        "        fold_preds1 = np.concatenate(fold_preds1).flatten()\n",
        "        fold_preds2 = np.concatenate(fold_preds2).flatten()\n",
        "        test_preds += (fold_preds+fold_preds1+fold_preds2) / (3*CONFIG['n_fold'])\n",
        "\n",
        "temp_df = pd.DataFrame({image_pred_col: test_preds}, index=df_test.index)\n",
        "df_test = df_test.join(temp_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T09:27:44.9386Z",
          "iopub.execute_input": "2024-09-06T09:27:44.939337Z",
          "iopub.status.idle": "2024-09-06T09:27:49.692464Z",
          "shell.execute_reply.started": "2024-09-06T09:27:44.939289Z",
          "shell.execute_reply": "2024-09-06T09:27:49.691184Z"
        },
        "trusted": true,
        "id": "kmKOAVgbL2iJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T09:27:51.777934Z",
          "iopub.execute_input": "2024-09-06T09:27:51.778722Z",
          "iopub.status.idle": "2024-09-06T09:27:51.807658Z",
          "shell.execute_reply.started": "2024-09-06T09:27:51.778689Z",
          "shell.execute_reply": "2024-09-06T09:27:51.80684Z"
        },
        "trusted": true,
        "id": "ke2X8SSPL2iJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import h5py\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import io\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "epoch_for_preds = 1\n",
        "model_path = \"/kaggle/input/fork-of-isic-2024-imagenet-train-oof-preds-pub/\"\n",
        "\n",
        "class ISICDataset(Dataset):\n",
        "    def __init__(self, hdf5_file, isic_ids, targets=None, transform=None):\n",
        "        self.hdf5_file = h5py.File(hdf5_file, 'r')  # Keep file open\n",
        "        self.isic_ids = isic_ids\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.isic_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_bytes = self.hdf5_file[self.isic_ids[idx]][()]\n",
        "        img = Image.open(io.BytesIO(img_bytes))\n",
        "        img = np.array(img)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=img)\n",
        "            img = transformed['image']\n",
        "\n",
        "        target = self.targets[idx] if self.targets is not None else torch.tensor(-1)\n",
        "        return img, target\n",
        "\n",
        "    def __del__(self):\n",
        "        self.hdf5_file.close()  # Ensure file is closed when object is destroyed\n",
        "\n",
        "# Define the albumentations transformation\n",
        "base_transform = A.Compose([\n",
        "    A.Resize(192, 192),\n",
        "     A.Transpose(p=0.5), A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5), A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5), A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "def setup_model(num_classes=2):\n",
        "    return timm.create_model('tf_efficientnetv2_b1', pretrained=False, num_classes=num_classes)\n",
        "\n",
        "def load_models(folds, device):\n",
        "    models = []\n",
        "    for fold in folds:\n",
        "        model = setup_model().to(device)\n",
        "        model.load_state_dict(torch.load(f'{model_path}model_fold_{fold}_epoch_{epoch_for_preds}.pth', map_location=device))\n",
        "        model.eval()\n",
        "        models.append(model)\n",
        "    return models\n",
        "\n",
        "@torch.no_grad()  # Apply no_grad to the entire function\n",
        "def ensemble_predict(models, test_loader, device):\n",
        "    all_predictions = []\n",
        "    for inputs, _ in tqdm(test_loader, desc=\"Predicting\"):\n",
        "        inputs = inputs.to(device)\n",
        "        fold_predictions = torch.stack([model(inputs).softmax(dim=1)[:, 1] for model in models])\n",
        "        avg_predictions = fold_predictions.mean(dim=0)\n",
        "        all_predictions.extend(avg_predictions.cpu().numpy())\n",
        "    return all_predictions\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:37:14.103356Z",
          "iopub.execute_input": "2024-09-06T08:37:14.103986Z",
          "iopub.status.idle": "2024-09-06T08:37:14.12644Z",
          "shell.execute_reply.started": "2024-09-06T08:37:14.103948Z",
          "shell.execute_reply": "2024-09-06T08:37:14.125044Z"
        },
        "trusted": true,
        "id": "rZysgCBGL2iJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''TEST_HDF5_FILE_PATH = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n",
        "\n",
        "# Set up CUDA if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# folds to use for pred\n",
        "folds = [0, 1, 2, 3, 4]\n",
        "\n",
        "models = load_models(folds, device)\n",
        "\n",
        "# Prepare your test dataset\n",
        "test_dataset1 = ISICDataset(\n",
        "    hdf5_file=TEST_HDF5_FILE_PATH,\n",
        "    isic_ids=df_test.index.values,  #minor change here from\n",
        "    transform=base_transform,\n",
        ")\n",
        "test_dataset2 = ISICDataset(\n",
        "    hdf5_file=TEST_HDF5_FILE_PATH,\n",
        "    isic_ids=df_test.index.values,  #minor change here from\n",
        "    transform=base_transform,\n",
        ")\n",
        "test_dataset3 = ISICDataset(\n",
        "    hdf5_file=TEST_HDF5_FILE_PATH,\n",
        "    isic_ids=df_test.index.values,  #minor change here from\n",
        "    transform=base_transform,\n",
        ")\n",
        "\n",
        "# Create test data loader\n",
        "test_loader1 = DataLoader(test_dataset1, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader2 = DataLoader(test_dataset2, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader3 = DataLoader(test_dataset3, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Run predictions\n",
        "predictions1 = ensemble_predict(models, test_loader1, device)\n",
        "predictions2 = ensemble_predict(models, test_loader2, device)\n",
        "predictions3 = ensemble_predict(models, test_loader3, device)\n",
        "\n",
        "all_predictions = np.stack((predictions1, predictions2, predictions3), axis = 0)\n",
        "print(all_predictions)\n",
        "predictions = np.mean(all_predictions, axis=0)\n",
        "\n",
        "\n",
        "# Create a new DataFrame with predictions\n",
        "temp_df = pd.DataFrame({image_pred_col: predictions}, index=df_test.index)\n",
        "\n",
        "# Join the predictions to df_test\n",
        "df_test = df_test.join(temp_df)\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:37:22.074934Z",
          "iopub.execute_input": "2024-09-06T08:37:22.075279Z",
          "iopub.status.idle": "2024-09-06T08:37:24.099788Z",
          "shell.execute_reply.started": "2024-09-06T08:37:22.075253Z",
          "shell.execute_reply": "2024-09-06T08:37:24.098225Z"
        },
        "trusted": true,
        "id": "aUoFHlGbL2iJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optuna HyperParam Tuned Models"
      ],
      "metadata": {
        "id": "EbPEjtNVL2iJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class SelectColumns(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return X[self.columns]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:39:57.035452Z",
          "iopub.execute_input": "2024-09-06T08:39:57.035819Z",
          "iopub.status.idle": "2024-09-06T08:39:57.041711Z",
          "shell.execute_reply.started": "2024-09-06T08:39:57.03579Z",
          "shell.execute_reply": "2024-09-06T08:39:57.040717Z"
        },
        "trusted": true,
        "id": "i1dlWyxlL2iJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_params = {\n",
        "    'objective':        'binary',\n",
        "    'verbosity':        -1,\n",
        "    'n_iter':           200,\n",
        "    'boosting_type':    'gbdt',\n",
        "    'random_state':     seed,\n",
        "    'lambda_l1':        0.08758718919397321,\n",
        "    'lambda_l2':        0.0039689175176025465,\n",
        "    'learning_rate':    0.03231007103195577,\n",
        "    'max_depth':        4,\n",
        "    'num_leaves':       103,\n",
        "    'colsample_bytree': 0.8329551585827726,\n",
        "    'colsample_bynode': 0.4025961355653304,\n",
        "    'bagging_fraction': 0.7738954452473223,\n",
        "    'bagging_freq':     4,\n",
        "    'min_data_in_leaf': 85,\n",
        "    'scale_pos_weight': 2.7984184778875543,\n",
        "}\n",
        "\n",
        "lgb_model = Pipeline([\n",
        "    ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n",
        "    ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio , random_state=seed)),\n",
        "    ('filter', SelectColumns(feature_cols_without_img)),\n",
        "    ('classifier', lgb.LGBMClassifier(**lgb_params)),\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:40:00.1157Z",
          "iopub.execute_input": "2024-09-06T08:40:00.116068Z",
          "iopub.status.idle": "2024-09-06T08:40:00.12367Z",
          "shell.execute_reply.started": "2024-09-06T08:40:00.11604Z",
          "shell.execute_reply": "2024-09-06T08:40:00.122652Z"
        },
        "trusted": true,
        "id": "pLhrXFNPL2iK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cb_params = {\n",
        "    'loss_function':     'Logloss',\n",
        "    'iterations':        200,\n",
        "    'verbose':           False,\n",
        "    'random_state':      seed,\n",
        "    'max_depth':         7,\n",
        "    'learning_rate':     0.06936242010150652,\n",
        "    'scale_pos_weight':  2.6149345838209532,\n",
        "    'l2_leaf_reg':       6.216113851699493,\n",
        "    'subsample':         0.6249261779711819,\n",
        "    'min_data_in_leaf':  24,\n",
        "    'cat_features':      cat_cols,\n",
        "}\n",
        "\n",
        "cb_model = Pipeline([\n",
        "    ('sampler_1', RandomOverSampler(sampling_strategy= 0.003 , random_state=seed)),\n",
        "    ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio , random_state=seed)),\n",
        "    ('classifier', cb.CatBoostClassifier(**cb_params)),\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:40:02.458308Z",
          "iopub.execute_input": "2024-09-06T08:40:02.458725Z",
          "iopub.status.idle": "2024-09-06T08:40:02.473103Z",
          "shell.execute_reply.started": "2024-09-06T08:40:02.458694Z",
          "shell.execute_reply": "2024-09-06T08:40:02.472081Z"
        },
        "trusted": true,
        "id": "Gj-iI3BpL2iK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_params = {\n",
        "    'enable_categorical': True,\n",
        "    'tree_method':        'hist',\n",
        "    'random_state':       seed,\n",
        "    'learning_rate':      0.08501257473292347,\n",
        "    'lambda':             8.879624125465703,\n",
        "    'alpha':              0.6779926606782505,\n",
        "    'max_depth':          6,\n",
        "    'subsample':          0.6012681388711075,\n",
        "    'colsample_bytree':   0.8437772277074493,\n",
        "    'colsample_bylevel':  0.5476090898823716,\n",
        "    'colsample_bynode':   0.9928601203635129,\n",
        "    'scale_pos_weight':   3.29440313334688,\n",
        "}\n",
        "\n",
        "xgb_model = Pipeline([\n",
        "    ('sampler_1', RandomOverSampler(sampling_strategy=0.003 , random_state=seed)),\n",
        "    ('sampler_2', RandomUnderSampler(sampling_strategy=sampling_ratio , random_state=seed)),\n",
        "    ('classifier', xgb.XGBClassifier(**xgb_params)),\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:40:04.741779Z",
          "iopub.execute_input": "2024-09-06T08:40:04.742407Z",
          "iopub.status.idle": "2024-09-06T08:40:04.749014Z",
          "shell.execute_reply.started": "2024-09-06T08:40:04.742361Z",
          "shell.execute_reply": "2024-09-06T08:40:04.748103Z"
        },
        "trusted": true,
        "id": "ca9TKBoNL2iK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = VotingClassifier([\n",
        "    ('lgb', lgb_model), ('cb', cb_model), ('xgb', xgb_model),\n",
        "], voting='soft')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:40:14.661521Z",
          "iopub.execute_input": "2024-09-06T08:40:14.662166Z",
          "iopub.status.idle": "2024-09-06T08:40:14.668976Z",
          "shell.execute_reply.started": "2024-09-06T08:40:14.662134Z",
          "shell.execute_reply": "2024-09-06T08:40:14.668016Z"
        },
        "trusted": true,
        "id": "4gYwe5qML2iK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross Validation"
      ],
      "metadata": {
        "id": "kzZElCZIL2iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_train[feature_cols]\n",
        "y = df_train[target_col]\n",
        "groups = df_train[group_col]\n",
        "cv = StratifiedGroupKFold(5, shuffle=True, random_state=seed)\n",
        "\n",
        "val_score = cross_val_score(\n",
        "    estimator=estimator,\n",
        "    X=X, y=y,\n",
        "    cv=cv,\n",
        "    groups=groups,\n",
        "    scoring=custom_metric,\n",
        ")\n",
        "\n",
        "np.mean(val_score), val_score"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:40:19.196106Z",
          "iopub.execute_input": "2024-09-06T08:40:19.196506Z",
          "iopub.status.idle": "2024-09-06T08:43:45.030573Z",
          "shell.execute_reply.started": "2024-09-06T08:40:19.196474Z",
          "shell.execute_reply": "2024-09-06T08:43:45.029605Z"
        },
        "trusted": true,
        "id": "WipIGmd6L2iK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "2GTrkvsQL2iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df_train[feature_cols], df_train[target_col]\n",
        "\n",
        "estimator.fit(X, y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T08:44:08.544619Z",
          "iopub.execute_input": "2024-09-06T08:44:08.545363Z",
          "iopub.status.idle": "2024-09-06T08:44:55.154614Z",
          "shell.execute_reply.started": "2024-09-06T08:44:08.545318Z",
          "shell.execute_reply": "2024-09-06T08:44:55.153591Z"
        },
        "trusted": true,
        "id": "wwa4d8_YL2iK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "2QIsmWp7L2iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T09:28:34.262091Z",
          "iopub.execute_input": "2024-09-06T09:28:34.262799Z",
          "iopub.status.idle": "2024-09-06T09:28:34.288388Z",
          "shell.execute_reply.started": "2024-09-06T09:28:34.262767Z",
          "shell.execute_reply": "2024-09-06T09:28:34.28746Z"
        },
        "trusted": true,
        "id": "kjD1no48L2iK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_subm['target'] = estimator.predict_proba(df_test[feature_cols])[:, 1]\n",
        "\n",
        "df_subm.to_csv('submission.csv')\n",
        "df_subm.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-06T09:28:36.941584Z",
          "iopub.execute_input": "2024-09-06T09:28:36.942195Z",
          "iopub.status.idle": "2024-09-06T09:28:37.047058Z",
          "shell.execute_reply.started": "2024-09-06T09:28:36.942164Z",
          "shell.execute_reply": "2024-09-06T09:28:37.046309Z"
        },
        "trusted": true,
        "id": "5zDsRd44L2iK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5y2EsOBL2iO"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}